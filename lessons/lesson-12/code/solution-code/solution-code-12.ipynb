{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS_HK_12 | Class 12 | NLP with Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Demo\n",
    "\n",
    "If you haven't installed spacy yet, use:\n",
    "```\n",
    "pip install spacy --yes\n",
    "python -m spacy.en.download\n",
    "```\n",
    "This downloads about 500 MB of data.\n",
    "\n",
    "Another popular package, `nltk`, can be installed as follows (you can skip this for now):\n",
    "\n",
    "```\n",
    "pip install nltk --yes\n",
    "python -m nltk.downloader all\n",
    "```\n",
    "\n",
    "This also downloads a lot of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load StumbleUpon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2  http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3  http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4  http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "2  {\"title\":\"Fruits that Fight the Flu fruits tha...           health   \n",
       "3  {\"title\":\"10 Foolproof Tips for Better Sleep \"...           health   \n",
       "4  {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...           sports   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "1               0.574147     3.677966           0.508021           0.288770   \n",
       "2               0.996526     2.382883           0.562016           0.321705   \n",
       "3               0.801248     1.543103           0.400000           0.100000   \n",
       "4               0.719157     2.676471           0.500000           0.222222   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "1           0.213904           0.144385   \n",
       "2           0.120155           0.042636   \n",
       "3           0.016667           0.000000   \n",
       "4           0.123457           0.043210   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "1                        ...                                     40   \n",
       "2                        ...                                     55   \n",
       "3                        ...                                     24   \n",
       "4                        ...                                     14   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "1                0                            4973            187   \n",
       "2                0                            2240            258   \n",
       "3                0                            2737            120   \n",
       "4                0                           12032            162   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941               0.079130     0   \n",
       "1                9               0.181818               0.125448     1   \n",
       "2               11               0.166667               0.057613     1   \n",
       "3                5               0.041667               0.100858     1   \n",
       "4               10               0.098765               0.082569     0   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1  The Fully Electronic Futuristic Starting Gun T...   \n",
       "2  Fruits that Fight the Flu fruits that fight th...   \n",
       "3                10 Foolproof Tips for Better Sleep    \n",
       "4  The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "1  And that can be carried on a plane without the...  \n",
       "2  Apples The most popular source of antioxidants...  \n",
       "3  There was a period in my life when I had a lot...  \n",
       "4  Jersey sales is a curious business Whether you...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"../../assets/dataset/stumbleupon.tsv\", sep='\\t',\n",
    "                  encoding=\"utf-8\")\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.en.English at 0x10433fd10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load spacy\n",
    "\n",
    "from spacy.en import English\n",
    "nlp_toolkit = English()\n",
    "nlp_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to load `spacy`:\n",
    "```\n",
    "import spacy\n",
    "nlp_toolkit = spacy.load(\"en\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: IBM\n",
      "\t Phrase type: nsubj\n",
      "\t Is the word a known entity type? ORG\n",
      "\t Lemma: ibm\n",
      "\t Parent of this word: see\n",
      "Word: sees\n",
      "\t Phrase type: ROOT\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: see\n",
      "\t Parent of this word: see\n",
      "Word: holographic\n",
      "\t Phrase type: amod\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: holographic\n",
      "\t Parent of this word: call\n",
      "Word: calls\n",
      "\t Phrase type: dobj\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: call\n",
      "\t Parent of this word: see\n",
      "Word: ,\n",
      "\t Phrase type: punct\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: ,\n",
      "\t Parent of this word: call\n",
      "Word: air\n",
      "\t Phrase type: compound\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: air\n",
      "\t Parent of this word: breathing\n",
      "Word: breathing\n",
      "\t Phrase type: compound\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: breathing\n",
      "\t Parent of this word: battery\n",
      "Word: batteries\n",
      "\t Phrase type: appos\n",
      "\t Is the word a known entity type? No\n",
      "\t Lemma: battery\n",
      "\t Parent of this word: call\n"
     ]
    }
   ],
   "source": [
    "title = u\"IBM sees holographic calls, air breathing batteries\"\n",
    "parsed = nlp_toolkit(title)\n",
    "\n",
    "for (i, word) in enumerate(parsed): \n",
    "    print \"Word: {}\".format(word)\n",
    "    print \"\\t Phrase type: {}\".format(word.dep_)\n",
    "    print \"\\t Is the word a known entity type? {}\".format(\n",
    "        word.ent_type_  if word.ent_type_ else \"No\")\n",
    "    print \"\\t Lemma: {}\".format(word.lemma_)\n",
    "    print \"\\t Parent of this word: {}\".format(word.head.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Page Titles\n",
    "\n",
    "Let's see if we can find organizations in our page titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fashion lane American Wild Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valet The Handbook 31 Days 31 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Financial News Breaking US Internatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Tip of the Cap to The Greatest Iron Man of T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title\n",
       "0   IBM Sees Holographic Calls Air Breathing Batte...\n",
       "6                   fashion lane American Wild Child \n",
       "8                  Valet The Handbook 31 Days 31 days\n",
       "10  Business Financial News Breaking US Internatio...\n",
       "11  A Tip of the Cap to The Greatest Iron Man of T..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def references_organization(title):\n",
    "    parsed = nlp_toolkit(title)\n",
    "    return any([word.ent_type_ == 'ORG' for word in parsed])\n",
    "\n",
    "data['references_organization'] = data['title'].fillna(u'').map(references_organization)\n",
    "\n",
    "# Take a look\n",
    "data[data.references_organization][['title']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Write a function to identify titles that mention an organization (ORG) and a person (PERSON).\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Genevieve Morton Swimsuit by Tyler Rose Swimwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Alyssa Miller Swimsuit by Charlie by Matthew Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Heidi s Favorite Snacks Heidi Klum on AOL heid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Jessica Gomes Swimsuit by Beach Bunny Swimwear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Burton adidas Billabong Vans Converse Nike Oak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "29   Genevieve Morton Swimsuit by Tyler Rose Swimwe...\n",
       "44   Alyssa Miller Swimsuit by Charlie by Matthew Z...\n",
       "91   Heidi s Favorite Snacks Heidi Klum on AOL heid...\n",
       "126  Jessica Gomes Swimsuit by Beach Bunny Swimwear...\n",
       "162  Burton adidas Billabong Vans Converse Nike Oak..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exercise solution\n",
    "\n",
    "def references_org_person(title):\n",
    "    parsed = nlp_toolkit(title)\n",
    "    contains_org = any([word.ent_type_ == 'ORG' for word in parsed])\n",
    "    contains_person = any([word.ent_type_ == 'PERSON' for word in parsed])\n",
    "    return contains_org and contains_person\n",
    "\n",
    "data['references_org_person'] = data['title'].fillna(u'').map(references_org_person)\n",
    "\n",
    "# Take a look\n",
    "data[data.references_org_person][['title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2  http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3  http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4  http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "2  {\"title\":\"Fruits that Fight the Flu fruits tha...           health   \n",
       "3  {\"title\":\"10 Foolproof Tips for Better Sleep \"...           health   \n",
       "4  {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...           sports   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "1               0.574147     3.677966           0.508021           0.288770   \n",
       "2               0.996526     2.382883           0.562016           0.321705   \n",
       "3               0.801248     1.543103           0.400000           0.100000   \n",
       "4               0.719157     2.676471           0.500000           0.222222   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "1           0.213904           0.144385   \n",
       "2           0.120155           0.042636   \n",
       "3           0.016667           0.000000   \n",
       "4           0.123457           0.043210   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "1                        ...                                     40   \n",
       "2                        ...                                     55   \n",
       "3                        ...                                     24   \n",
       "4                        ...                                     14   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "1                0                            4973            187   \n",
       "2                0                            2240            258   \n",
       "3                0                            2737            120   \n",
       "4                0                           12032            162   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941               0.079130     0   \n",
       "1                9               0.181818               0.125448     1   \n",
       "2               11               0.166667               0.057613     1   \n",
       "3                5               0.041667               0.100858     1   \n",
       "4               10               0.098765               0.082569     0   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1  The Fully Electronic Futuristic Starting Gun T...   \n",
       "2  Fruits that Fight the Flu fruits that fight th...   \n",
       "3                10 Foolproof Tips for Better Sleep    \n",
       "4  The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "1  And that can be carried on a plane without the...  \n",
       "2  Apples The most popular source of antioxidants...  \n",
       "3  There was a period in my life when I had a lot...  \n",
       "4  Jersey sales is a curious business Whether you...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"../../assets/dataset/stumbleupon.tsv\", sep='\\t')\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" Of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender.  \n",
    "\n",
    "A description of the columns is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Let's try extracting some of the text content.\n",
    "> ### Create a feature for the title containing 'recipe'. Is the % of evegreen websites higher or lower on pages that have recipe in the the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 1: Create a function to check for this\n",
    "\n",
    "def has_recipe(text_in):\n",
    "    try:\n",
    "        if 'recipe' in str(text_in).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except: \n",
    "        return 0\n",
    "        \n",
    "data['recipe'] = data['title'].map(has_recipe)\n",
    "\n",
    "# Option 2: lambda functions\n",
    "\n",
    "#data['recipe'] = data['title'].map(lambda t: 1 if 'recipe' in str(t).lower() else 0)\n",
    "\n",
    "\n",
    "# Option 3: string functions\n",
    "data['recipe'] = data['title'].str.contains('recipe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Use of the Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer: Convert a collection of text documents to a matrix of token counts\n",
    " - max_features : *int* or *None*, `default=None`\n",
    "     - If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "This parameter is ignored if vocabulary is not None.\n",
    " - ngram_range\n",
    "     - ngram_range : tuple (min_n, max_n)\n",
    "The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used.\n",
    " - stop_words\n",
    "     - If â€˜englishâ€™, a built-in stop word list for English is used.\n",
    "If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if analyzer == 'word'.\n",
    "If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.\n",
    " - binary\n",
    "     - If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = data['title'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1000, \n",
    "                             ngram_range=(1, 2), \n",
    "                             stop_words='english',\n",
    "                             binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=u'english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectorizer.fit(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectorizer.transform(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7395x1000 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 25164 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Build a random forest model to predict evergreeness of a website using the title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=u'english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectorizer.fit(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'000',\n",
       " u'10',\n",
       " u'10 best',\n",
       " u'10 things',\n",
       " u'10 ways',\n",
       " u'100',\n",
       " u'101',\n",
       " u'101 cookbooks',\n",
       " u'11',\n",
       " u'12',\n",
       " u'13',\n",
       " u'14',\n",
       " u'15',\n",
       " u'16',\n",
       " u'17',\n",
       " u'18',\n",
       " u'20',\n",
       " u'2007',\n",
       " u'2008',\n",
       " u'2008 sports',\n",
       " u'2009',\n",
       " u'2010',\n",
       " u'2010 sports',\n",
       " u'2011',\n",
       " u'2011 sports',\n",
       " u'2012',\n",
       " u'2013',\n",
       " u'2013 check',\n",
       " u'2013 sports',\n",
       " u'22',\n",
       " u'24',\n",
       " u'25',\n",
       " u'30',\n",
       " u'3d',\n",
       " u'50',\n",
       " u'8211',\n",
       " u'8217',\n",
       " u'8230',\n",
       " u'abs',\n",
       " u'accessories',\n",
       " u'actually',\n",
       " u'adventures',\n",
       " u'advice',\n",
       " u'air',\n",
       " u'alcohol',\n",
       " u'allrecipes',\n",
       " u'allrecipes com',\n",
       " u'almond',\n",
       " u'alton brown',\n",
       " u'amazing',\n",
       " u'america',\n",
       " u'american',\n",
       " u'analysis',\n",
       " u'anderson',\n",
       " u'android',\n",
       " u'angeles',\n",
       " u'angeles slideshows',\n",
       " u'anxiety',\n",
       " u'apple',\n",
       " u'apple pie',\n",
       " u'apples',\n",
       " u'apps',\n",
       " u'archive',\n",
       " u'art',\n",
       " u'artichoke',\n",
       " u'asian',\n",
       " u'athletes',\n",
       " u'atlantic',\n",
       " u'attack',\n",
       " u'avocado',\n",
       " u'awesome',\n",
       " u'baby',\n",
       " u'bacon',\n",
       " u'bad',\n",
       " u'bake',\n",
       " u'baked',\n",
       " u'baker',\n",
       " u'bakers',\n",
       " u'baking',\n",
       " u'ball',\n",
       " u'balls',\n",
       " u'balsamic',\n",
       " u'banana',\n",
       " u'banana bread',\n",
       " u'bar',\n",
       " u'bar refaeli',\n",
       " u'bars',\n",
       " u'basil',\n",
       " u'bbc',\n",
       " u'bbc food',\n",
       " u'bbc news',\n",
       " u'bbq',\n",
       " u'beach',\n",
       " u'bean',\n",
       " u'beautiful',\n",
       " u'beauty',\n",
       " u'beef',\n",
       " u'beer',\n",
       " u'bell',\n",
       " u'benefits',\n",
       " u'best',\n",
       " u'best new',\n",
       " u'better',\n",
       " u'betty',\n",
       " u'betty crocker',\n",
       " u'big',\n",
       " u'biggest',\n",
       " u'birthday',\n",
       " u'biscuits',\n",
       " u'bites',\n",
       " u'black',\n",
       " u'black bean',\n",
       " u'blog',\n",
       " u'blog archive',\n",
       " u'blogs',\n",
       " u'blood',\n",
       " u'blue',\n",
       " u'blueberry',\n",
       " u'body',\n",
       " u'boost',\n",
       " u'boots',\n",
       " u'boston',\n",
       " u'bowl',\n",
       " u'boy',\n",
       " u'brain',\n",
       " u'bread',\n",
       " u'bread recipe',\n",
       " u'break',\n",
       " u'break com',\n",
       " u'breakfast',\n",
       " u'breaking',\n",
       " u'breaking news',\n",
       " u'broccoli',\n",
       " u'brooklyn',\n",
       " u'brooklyn decker',\n",
       " u'brown',\n",
       " u'brownie',\n",
       " u'brownies',\n",
       " u'brownies recipe',\n",
       " u'buffalo',\n",
       " u'buffalo chicken',\n",
       " u'build',\n",
       " u'burger',\n",
       " u'burgers',\n",
       " u'burn',\n",
       " u'business',\n",
       " u'butt',\n",
       " u'butter',\n",
       " u'butter cookies',\n",
       " u'buttercream',\n",
       " u'buttermilk',\n",
       " u'buy',\n",
       " u'cajun',\n",
       " u'cake',\n",
       " u'cake recipe',\n",
       " u'cakes',\n",
       " u'camera',\n",
       " u'cancer',\n",
       " u'candy',\n",
       " u'car',\n",
       " u'caramel',\n",
       " u'caramelized',\n",
       " u'care',\n",
       " u'carrot',\n",
       " u'casserole',\n",
       " u'casserole recipe',\n",
       " u'celebrity',\n",
       " u'cell',\n",
       " u'center',\n",
       " u'challenge',\n",
       " u'change',\n",
       " u'check',\n",
       " u'cheddar',\n",
       " u'cheese',\n",
       " u'cheese frosting',\n",
       " u'cheesecake',\n",
       " u'cheesecake recipe',\n",
       " u'cheesecakes',\n",
       " u'cheesy',\n",
       " u'chef',\n",
       " u'cherry',\n",
       " u'chic',\n",
       " u'chicago',\n",
       " u'chicken',\n",
       " u'chicken recipe',\n",
       " u'chicken recipes',\n",
       " u'children',\n",
       " u'chili',\n",
       " u'chinese',\n",
       " u'chip',\n",
       " u'chip cookies',\n",
       " u'chips',\n",
       " u'chocolate',\n",
       " u'chocolate cake',\n",
       " u'chocolate chip',\n",
       " u'chocolate peanut',\n",
       " u'christmas',\n",
       " u'cinnamon',\n",
       " u'cinnamon rolls',\n",
       " u'city',\n",
       " u'classic',\n",
       " u'clothes',\n",
       " u'clothing',\n",
       " u'clutch',\n",
       " u'cnn',\n",
       " u'cnn com',\n",
       " u'coconut',\n",
       " u'coffee',\n",
       " u'coffee cake',\n",
       " u'cold',\n",
       " u'collection',\n",
       " u'collection 2008',\n",
       " u'collection 2010',\n",
       " u'college',\n",
       " u'college fashion',\n",
       " u'collegehumor',\n",
       " u'collegehumor video',\n",
       " u'com',\n",
       " u'com insidershealth',\n",
       " u'com photos',\n",
       " u'common',\n",
       " u'community',\n",
       " u'computer',\n",
       " u'concept',\n",
       " u'control',\n",
       " u'cook',\n",
       " u'cookbooks',\n",
       " u'cooker',\n",
       " u'cookie',\n",
       " u'cookie dough',\n",
       " u'cookie recipe',\n",
       " u'cookies',\n",
       " u'cookies cream',\n",
       " u'cookies recipe',\n",
       " u'cookin',\n",
       " u'cooking',\n",
       " u'cooking food',\n",
       " u'cooking tips',\n",
       " u'cooks',\n",
       " u'cool',\n",
       " u'coolest',\n",
       " u'corn',\n",
       " u'costume',\n",
       " u'cranberry',\n",
       " u'crazy',\n",
       " u'cream',\n",
       " u'cream cheese',\n",
       " u'cream sauce',\n",
       " u'creamy',\n",
       " u'create',\n",
       " u'creative',\n",
       " u'crispy',\n",
       " u'crocker',\n",
       " u'crunch',\n",
       " u'crust',\n",
       " u'cuisine',\n",
       " u'culture',\n",
       " u'cup',\n",
       " u'cupcake',\n",
       " u'cupcakes',\n",
       " u'cups',\n",
       " u'cure',\n",
       " u'cures',\n",
       " u'current',\n",
       " u'cut',\n",
       " u'cute',\n",
       " u'cyanide',\n",
       " u'cyanide happiness',\n",
       " u'daily',\n",
       " u'dangerous',\n",
       " u'dark',\n",
       " u'dark chocolate',\n",
       " u'day',\n",
       " u'days',\n",
       " u'death',\n",
       " u'decker',\n",
       " u'decker si',\n",
       " u'delicious',\n",
       " u'denver',\n",
       " u'design',\n",
       " u'designer',\n",
       " u'designs',\n",
       " u'dessert',\n",
       " u'dessert recipe',\n",
       " u'dessert recipes',\n",
       " u'desserts',\n",
       " u'device',\n",
       " u'did',\n",
       " u'die',\n",
       " u'diet',\n",
       " u'dining',\n",
       " u'dinner',\n",
       " u'dip',\n",
       " u'dipping',\n",
       " u'diseases',\n",
       " u'dish',\n",
       " u'dishes',\n",
       " u'disorders',\n",
       " u'diy',\n",
       " u'does',\n",
       " u'doesn',\n",
       " u'dog',\n",
       " u'doing',\n",
       " u'don',\n",
       " u'dough',\n",
       " u'dress',\n",
       " u'dresses',\n",
       " u'drink',\n",
       " u'drugs',\n",
       " u'earth',\n",
       " u'easy',\n",
       " u'eat',\n",
       " u'eating',\n",
       " u'eats',\n",
       " u'edition',\n",
       " u'edition check',\n",
       " u'edition si',\n",
       " u'egg',\n",
       " u'eggs',\n",
       " u'elle',\n",
       " u'elle com',\n",
       " u'enchiladas',\n",
       " u'energy',\n",
       " u'entertainment',\n",
       " u'epic',\n",
       " u'epicurious',\n",
       " u'epicurious com',\n",
       " u'espresso',\n",
       " u'everyday',\n",
       " u'evolution',\n",
       " u'exercise',\n",
       " u'exercises',\n",
       " u'expensive',\n",
       " u'explosm',\n",
       " u'explosm net',\n",
       " u'eye',\n",
       " u'eyed',\n",
       " u'fabulous',\n",
       " u'face',\n",
       " u'facebook',\n",
       " u'facts',\n",
       " u'fake',\n",
       " u'fall',\n",
       " u'family',\n",
       " u'family kitchen',\n",
       " u'famous',\n",
       " u'fans',\n",
       " u'fashion',\n",
       " u'fashion week',\n",
       " u'fast',\n",
       " u'fast food',\n",
       " u'fat',\n",
       " u'favorite',\n",
       " u'feel',\n",
       " u'female',\n",
       " u'feta',\n",
       " u'field',\n",
       " u'fight',\n",
       " u'filled',\n",
       " u'film',\n",
       " u'finally',\n",
       " u'fitness',\n",
       " u'flickr',\n",
       " u'food',\n",
       " u'food blog',\n",
       " u'food cooking',\n",
       " u'food network',\n",
       " u'food photography',\n",
       " u'food recipes',\n",
       " u'foodie',\n",
       " u'foods',\n",
       " u'foods eat',\n",
       " u'football',\n",
       " u'fox',\n",
       " u'francisco',\n",
       " u'free',\n",
       " u'free online',\n",
       " u'french',\n",
       " u'french toast',\n",
       " u'fresh',\n",
       " u'fried',\n",
       " u'fries',\n",
       " u'frosting',\n",
       " u'fruit',\n",
       " u'fruits',\n",
       " u'fudge',\n",
       " u'fun',\n",
       " u'funny',\n",
       " u'funny pictures',\n",
       " u'future',\n",
       " u'future technology',\n",
       " u'g4tv',\n",
       " u'g4tv com',\n",
       " u'gallery',\n",
       " u'game',\n",
       " u'games',\n",
       " u'garden',\n",
       " u'garlic',\n",
       " u'geek',\n",
       " u'german',\n",
       " u'gets',\n",
       " u'getting',\n",
       " u'gifs',\n",
       " u'ginger',\n",
       " u'girl',\n",
       " u'girls',\n",
       " u'glass',\n",
       " u'global',\n",
       " u'gluten',\n",
       " u'gluten free',\n",
       " u'goes',\n",
       " u'going',\n",
       " u'gomes',\n",
       " u'good',\n",
       " u'google',\n",
       " u'got',\n",
       " u'gourmet',\n",
       " u'granola',\n",
       " u'great',\n",
       " u'greatest',\n",
       " u'greek',\n",
       " u'green',\n",
       " u'grilled',\n",
       " u'grilled cheese',\n",
       " u'guide',\n",
       " u'guy',\n",
       " u'habits',\n",
       " u'hair',\n",
       " u'halloween',\n",
       " u'happens',\n",
       " u'happiness',\n",
       " u'happy',\n",
       " u'hate',\n",
       " u'having',\n",
       " u'headlines',\n",
       " u'health',\n",
       " u'health benefits',\n",
       " u'health com',\n",
       " u'healthier',\n",
       " u'healthy',\n",
       " u'healthy food',\n",
       " u'healthy recipes',\n",
       " u'heart',\n",
       " u'heather',\n",
       " u'help',\n",
       " u'high',\n",
       " u'history',\n",
       " u'holiday',\n",
       " u'home',\n",
       " u'homemade',\n",
       " u'honey',\n",
       " u'hot',\n",
       " u'hot chocolate',\n",
       " u'hottest',\n",
       " u'house',\n",
       " u'human',\n",
       " u'hummus',\n",
       " u'humor',\n",
       " u'hungry',\n",
       " u'ice',\n",
       " u'ice cream',\n",
       " u'ideas',\n",
       " u'illustrated',\n",
       " u'illustrated swimsuit',\n",
       " u'image',\n",
       " u'images',\n",
       " u'improve',\n",
       " u'index',\n",
       " u'indie',\n",
       " u'indie clothing',\n",
       " u'indie urban',\n",
       " u'infographic',\n",
       " u'information',\n",
       " u'ingredient',\n",
       " u'ingredients',\n",
       " u'inside',\n",
       " u'insidershealth',\n",
       " u'insidershealth com',\n",
       " u'inspiration',\n",
       " u'inspired',\n",
       " u'international',\n",
       " u'internet',\n",
       " u'ipad',\n",
       " u'iphone',\n",
       " u'irish',\n",
       " u'iron',\n",
       " u'italian',\n",
       " u'items',\n",
       " u'ivillage',\n",
       " u'jessica',\n",
       " u'jessica gomes',\n",
       " u'joe',\n",
       " u'joy',\n",
       " u'joy baker',\n",
       " u'just',\n",
       " u'kate',\n",
       " u'kate upton',\n",
       " u'key',\n",
       " u'kick',\n",
       " u'kids',\n",
       " u'kill',\n",
       " u'kitchen',\n",
       " u'kitchens',\n",
       " u'kitchens food',\n",
       " u'know',\n",
       " u'la',\n",
       " u'lasagna',\n",
       " u'latest',\n",
       " u'league',\n",
       " u'learn',\n",
       " u'lemon',\n",
       " u'lemonade',\n",
       " u'life',\n",
       " u'life style',\n",
       " u'lifestyle',\n",
       " u'light',\n",
       " u'like',\n",
       " u'lime',\n",
       " u'list',\n",
       " u'little',\n",
       " u'live',\n",
       " u'living',\n",
       " u'll',\n",
       " u'local',\n",
       " u'london',\n",
       " u'london 2012',\n",
       " u'long',\n",
       " u'longer',\n",
       " u'look',\n",
       " u'looks',\n",
       " u'los',\n",
       " u'los angeles',\n",
       " u'lose',\n",
       " u'loss',\n",
       " u'lost',\n",
       " u'love',\n",
       " u'low',\n",
       " u'lunch',\n",
       " u'mac',\n",
       " u'mac cheese',\n",
       " u'macaroni',\n",
       " u'macaroni cheese',\n",
       " u'machine',\n",
       " u'magazine',\n",
       " u'make',\n",
       " u'makes',\n",
       " u'making',\n",
       " u'man',\n",
       " u'management',\n",
       " u'maple',\n",
       " u'marijuana',\n",
       " u'marshmallow',\n",
       " u'martha',\n",
       " u'martha stewart',\n",
       " u'mashed',\n",
       " u'meal',\n",
       " u'meals',\n",
       " u'meat',\n",
       " u'meatballs',\n",
       " u'media',\n",
       " u'medical',\n",
       " u'medicine',\n",
       " u'meme',\n",
       " u'memory',\n",
       " u'men',\n",
       " u'men health',\n",
       " u'mental',\n",
       " u'menus',\n",
       " u'mess',\n",
       " u'mexican',\n",
       " u'microsoft',\n",
       " u'mike',\n",
       " u'milk',\n",
       " u'miller',\n",
       " u'million',\n",
       " u'mind',\n",
       " u'mini',\n",
       " u'mint',\n",
       " u'minutes',\n",
       " u'mit',\n",
       " u'mix',\n",
       " u'mnn',\n",
       " u'mobile',\n",
       " u'model',\n",
       " u'model 2011',\n",
       " u'models',\n",
       " u'modern',\n",
       " u'mom',\n",
       " u'mom spark',\n",
       " u'moments',\n",
       " u'money',\n",
       " u'monkey',\n",
       " u'mores',\n",
       " u'morning',\n",
       " u'mother',\n",
       " u'movie',\n",
       " u'movies',\n",
       " u'mozzarella',\n",
       " u'muffins',\n",
       " u'museum',\n",
       " u'mushroom',\n",
       " u'mushrooms',\n",
       " u'music',\n",
       " u'mustard',\n",
       " u'nail',\n",
       " u'nanny',\n",
       " u'national',\n",
       " u'natural',\n",
       " u'need',\n",
       " u'net',\n",
       " u'network',\n",
       " u'network kitchens',\n",
       " u'new',\n",
       " u'new york',\n",
       " u'news',\n",
       " u'nfl',\n",
       " u'nice',\n",
       " u'night',\n",
       " u'npr',\n",
       " u'nutella',\n",
       " u'nutrition',\n",
       " u'oatmeal',\n",
       " u'obama',\n",
       " u'official',\n",
       " u'oh',\n",
       " u'oil',\n",
       " u'old',\n",
       " u'olive',\n",
       " u'olympic',\n",
       " u'olympics',\n",
       " u'onion',\n",
       " u'online',\n",
       " u'open',\n",
       " u'orange',\n",
       " u'oreo',\n",
       " u'oven',\n",
       " u'page',\n",
       " u'pain',\n",
       " u'pan',\n",
       " u'pancakes',\n",
       " u'parents',\n",
       " u'paris',\n",
       " u'parmesan',\n",
       " u'parsley',\n",
       " u'party',\n",
       " u'pasta',\n",
       " u'pastry',\n",
       " u'pea',\n",
       " u'peach',\n",
       " u'peanut',\n",
       " u'peanut butter',\n",
       " u'peas',\n",
       " u'pecan',\n",
       " u'people',\n",
       " u'pepper',\n",
       " u'peppermint',\n",
       " u'perfect',\n",
       " u'person',\n",
       " u'personal',\n",
       " u'pesto',\n",
       " u'phone',\n",
       " u'phones',\n",
       " u'photo',\n",
       " u'photo gallery',\n",
       " u'photography',\n",
       " u'photos',\n",
       " u'photos sports',\n",
       " u'pic',\n",
       " u'pics',\n",
       " u'picture',\n",
       " u'pictures',\n",
       " u'pie',\n",
       " u'pie recipe',\n",
       " u'pies',\n",
       " u'pig',\n",
       " u'pink',\n",
       " u'pioneer',\n",
       " u'pioneer woman',\n",
       " u'pizza',\n",
       " u'play',\n",
       " u'player',\n",
       " u'playing',\n",
       " u'police',\n",
       " u'polyvore',\n",
       " u'pop',\n",
       " u'pops',\n",
       " u'popular',\n",
       " u'pork',\n",
       " u'post',\n",
       " u'pot',\n",
       " u'potato',\n",
       " u'potatoes',\n",
       " u'power',\n",
       " u'pretty',\n",
       " u'pretzel',\n",
       " u'prevent',\n",
       " u'print',\n",
       " u'pro',\n",
       " u'probably',\n",
       " u'products',\n",
       " u'project',\n",
       " u'pudding',\n",
       " u'pumpkin',\n",
       " u'quick',\n",
       " u'quotes',\n",
       " u'rainbow',\n",
       " u'random',\n",
       " u'raspberry',\n",
       " u'raw',\n",
       " u'ready',\n",
       " u'real',\n",
       " u'real simple',\n",
       " u'reality',\n",
       " u'really',\n",
       " u'reasons',\n",
       " u'recipe',\n",
       " u'recipe allrecipes',\n",
       " u'recipe blog',\n",
       " u'recipe epicurious',\n",
       " u'recipe food',\n",
       " u'recipe simply',\n",
       " u'recipes',\n",
       " u'recipes cooking',\n",
       " u'recipes food',\n",
       " u'recipes ivillage',\n",
       " u'record',\n",
       " u'red',\n",
       " u'red velvet',\n",
       " u'refaeli',\n",
       " u'refaeli si',\n",
       " u'remedies',\n",
       " u'report',\n",
       " u'research',\n",
       " u'restaurant',\n",
       " u'restaurants',\n",
       " u'results',\n",
       " u'retro',\n",
       " u'review',\n",
       " u'reviews',\n",
       " u'rice',\n",
       " u'right',\n",
       " u'rings',\n",
       " u'risk',\n",
       " u'roast',\n",
       " u'roasted',\n",
       " u'robot',\n",
       " u'roll',\n",
       " u'rolls',\n",
       " u'rosemary',\n",
       " u'rules',\n",
       " u'runway',\n",
       " u'salad',\n",
       " u'salmon',\n",
       " u'salsa',\n",
       " u'salt',\n",
       " u'salted',\n",
       " u'salted caramel',\n",
       " u'san',\n",
       " u'san francisco',\n",
       " u'sandwich',\n",
       " u'sandwiches',\n",
       " u'sauce',\n",
       " u'sauce recipe',\n",
       " u'sausage',\n",
       " u'save',\n",
       " u'savory',\n",
       " u'say',\n",
       " u'says',\n",
       " u'school',\n",
       " u'science',\n",
       " u'scones',\n",
       " u'scores',\n",
       " u'search',\n",
       " u'secret',\n",
       " u'self',\n",
       " u'served',\n",
       " u'set',\n",
       " u'sex',\n",
       " u'sexy',\n",
       " u'sharing',\n",
       " u'shoes',\n",
       " u'shop',\n",
       " u'shopping',\n",
       " u'shot',\n",
       " u'shots',\n",
       " u'shows',\n",
       " u'shrimp',\n",
       " u'si',\n",
       " u'si com',\n",
       " u'si swimsuit',\n",
       " u'sign',\n",
       " u'simple',\n",
       " u'simple recipes',\n",
       " u'simply',\n",
       " u'site',\n",
       " u'skin',\n",
       " u'skinny',\n",
       " u'sleep',\n",
       " u'slide',\n",
       " u'slideshows',\n",
       " u'slow',\n",
       " u'slow cooker',\n",
       " u'smart',\n",
       " u'smile',\n",
       " u'smitten',\n",
       " u'smitten kitchen',\n",
       " u'smoked',\n",
       " u'snack',\n",
       " u'snacks',\n",
       " u'soccer',\n",
       " u'soda',\n",
       " u'soft',\n",
       " u'solar',\n",
       " u'soon',\n",
       " u'soup',\n",
       " u'soup recipe',\n",
       " u'sour',\n",
       " u'source',\n",
       " u'south',\n",
       " u'southern',\n",
       " u'space',\n",
       " u'spaghetti',\n",
       " u'spark',\n",
       " u'speed',\n",
       " u'spice',\n",
       " u'spiced',\n",
       " u'spicy',\n",
       " u'spinach',\n",
       " u'sport',\n",
       " u'sports',\n",
       " u'sports illustrated',\n",
       " u'sports news',\n",
       " u'spring',\n",
       " u'star',\n",
       " u'stars',\n",
       " u'stay',\n",
       " u'steak',\n",
       " u'stewart',\n",
       " u'stewart recipes',\n",
       " u'stop',\n",
       " u'store',\n",
       " u'stories',\n",
       " u'story',\n",
       " u'strawberries',\n",
       " u'strawberry',\n",
       " u'street',\n",
       " u'street style',\n",
       " u'stress',\n",
       " u'students',\n",
       " u'study',\n",
       " u'stuffed',\n",
       " u'stupid',\n",
       " u'style',\n",
       " u'sugar',\n",
       " u'sugar cookies',\n",
       " u'sugarcrafter',\n",
       " u'summer',\n",
       " u'sun',\n",
       " u'super',\n",
       " u'super bowl',\n",
       " u'support',\n",
       " u'surface',\n",
       " u'sushi',\n",
       " u'sweet',\n",
       " u'sweet potato',\n",
       " u'swimsuit',\n",
       " u'swimsuit 2013',\n",
       " u'swimsuit collection',\n",
       " u'swimsuit edition',\n",
       " u'swimsuit photo',\n",
       " u'swimsuit photos',\n",
       " u'sylvia',\n",
       " u'sylvia anderson',\n",
       " u'symptoms',\n",
       " u'syrup',\n",
       " u'table',\n",
       " u'taco',\n",
       " u'tacos',\n",
       " u'takes',\n",
       " u'tart',\n",
       " u'taste',\n",
       " u'tasty',\n",
       " u'tea',\n",
       " u'teacher',\n",
       " u'team',\n",
       " u'tech',\n",
       " u'techflesh',\n",
       " u'techniques',\n",
       " u'technologies',\n",
       " u'technology',\n",
       " u'technology news',\n",
       " u'technology review',\n",
       " u'ted',\n",
       " u'teen',\n",
       " u'telegraph',\n",
       " u'test',\n",
       " u'thanksgiving',\n",
       " u'thing',\n",
       " u'things',\n",
       " u'think',\n",
       " u'threadsence',\n",
       " u'threat',\n",
       " u'thyme',\n",
       " u'time',\n",
       " u'times',\n",
       " u'tiny',\n",
       " u'tip',\n",
       " u'tips',\n",
       " u'toast',\n",
       " u'today',\n",
       " u'tomato',\n",
       " u'tomatoes',\n",
       " u'tools',\n",
       " u'touch',\n",
       " u'treats',\n",
       " u'treehugger',\n",
       " u'trends',\n",
       " u'trick',\n",
       " u'tricks',\n",
       " u'truffles',\n",
       " u'try',\n",
       " u'turkey',\n",
       " u'turn',\n",
       " u'turns',\n",
       " u'tutorial',\n",
       " u'tv',\n",
       " u'twice',\n",
       " u'uk',\n",
       " u'ultimate',\n",
       " u'unique',\n",
       " u'upton',\n",
       " u'urban',\n",
       " u'use',\n",
       " u'uses',\n",
       " u'using',\n",
       " u'valentine',\n",
       " u'valentine day',\n",
       " u'vanilla',\n",
       " u've',\n",
       " u'vegan',\n",
       " u'vegetables',\n",
       " u'vegetarian',\n",
       " u'velvet',\n",
       " u'video',\n",
       " u'videos',\n",
       " u'village',\n",
       " u'village voice',\n",
       " u'vintage',\n",
       " u'visual',\n",
       " u'voice',\n",
       " u'vs',\n",
       " u'wall',\n",
       " u'want',\n",
       " u'watch',\n",
       " u'water',\n",
       " u'way',\n",
       " u'ways',\n",
       " u'wear',\n",
       " u'weather',\n",
       " u'web',\n",
       " u'wedding',\n",
       " u'week',\n",
       " u'weekly',\n",
       " u'weight',\n",
       " u'weight loss',\n",
       " u'weird',\n",
       " u'welcome',\n",
       " u'wheat',\n",
       " u'white',\n",
       " u'white chocolate',\n",
       " u'wild',\n",
       " u'windows',\n",
       " u'wine',\n",
       " u'wings',\n",
       " u'winter',\n",
       " u'woman',\n",
       " u'woman cooks',\n",
       " u'womansday',\n",
       " u'womansday com',\n",
       " u'women',\n",
       " u'women fashion',\n",
       " u'won',\n",
       " u'work',\n",
       " u'workout',\n",
       " u'works',\n",
       " u'world',\n",
       " u'world news',\n",
       " u'worst',\n",
       " u'wrong',\n",
       " u'wtf',\n",
       " u'year',\n",
       " u'year old',\n",
       " u'years',\n",
       " u'yes',\n",
       " u'york',\n",
       " u'york best',\n",
       " u'york village',\n",
       " u'youtube',\n",
       " u'yummy',\n",
       " u'zucchini']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectorizer.transform(titles).toarray()\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.8457977   0.84227236  0.85285097  0.85817779  0.84943405], Average AUC 0.84970657521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=5)\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>oven</td>\n",
       "      <td>0.036416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>recipe</td>\n",
       "      <td>0.030366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>recipes</td>\n",
       "      <td>0.026174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>cup</td>\n",
       "      <td>0.018068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>butter</td>\n",
       "      <td>0.017531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Importance Score\n",
       "619     oven          0.036416\n",
       "721   recipe          0.030366\n",
       "722  recipes          0.026174\n",
       "238      cup          0.018068\n",
       "136   butter          0.017531"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What features of these are most important?\n",
    "model.fit(X, y)\n",
    "\n",
    "all_feature_names = vectorizer.get_feature_names()\n",
    "feature_importances = pd.DataFrame({'Features' : all_feature_names, 'Importance Score': model.feature_importances_})\n",
    "feature_importances.sort_values('Importance Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Build a random forest model to predict evergreeness of a website using the title features and quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.77186769  0.79788739  0.79929183  0.78153821  0.79671022], Average AUC 0.789459068337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>html_ratio</td>\n",
       "      <td>0.161160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>image_ratio</td>\n",
       "      <td>0.096132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>recipe</td>\n",
       "      <td>0.044196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>recipes</td>\n",
       "      <td>0.023174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features  Importance Score\n",
       "1000   html_ratio          0.161160\n",
       "1001  image_ratio          0.096132\n",
       "721        recipe          0.044196\n",
       "722       recipes          0.023174\n",
       "172     chocolate          0.015984"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X_text_features = vectorizer.transform(titles)\n",
    "\n",
    "# Identify the features you want from the original dataset\n",
    "other_features_columns = ['html_ratio', 'image_ratio']\n",
    "other_features = data[other_features_columns]\n",
    "\n",
    "# Stack them horizontally together\n",
    "# This takes all of the word/n-gram columns and appends on two more columns for `html_ratio` and `image_ratio`\n",
    "from scipy.sparse import hstack\n",
    "X = hstack((X_text_features, other_features)).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=5)\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))\n",
    "\n",
    "# What features of these are most important?\n",
    "model.fit(X, y)\n",
    "\n",
    "all_feature_names = vectorizer.get_feature_names() + other_features_columns\n",
    "feature_importances = pd.DataFrame({'Features' : all_feature_names, 'Importance Score': model.feature_importances_})\n",
    "feature_importances.sort_values('Importance Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise: Build a random forest model to predict evergreeness of a website using the body features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.84037684  0.85508004  0.84439174], Average AUC 0.846616206266\n"
     ]
    }
   ],
   "source": [
    "body_text = data['body'].fillna('')\n",
    "\n",
    "# Use `fit` to learn the vocabulary\n",
    "vectorizer.fit(body_text)\n",
    "\n",
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectorizer.transform(body_text).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise: Use `TfIdfVectorizer` instead of `CountVectorizer` - is this an improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.84027449  0.85374868  0.84420251], Average AUC 0.846075227667\n"
     ]
    }
   ],
   "source": [
    "titles = data['title'].fillna('')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 1000, \n",
    "                             ngram_range=(1, 2), \n",
    "                             stop_words='english')\n",
    "\n",
    "\n",
    "# Use `fit` to learn the vocabulary\n",
    "vectorizer.fit(body_text)\n",
    "\n",
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectorizer.transform(body_text).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
